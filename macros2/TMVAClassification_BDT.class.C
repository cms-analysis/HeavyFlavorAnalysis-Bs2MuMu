// Class: ReadBDT
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDT
TMVA Release   : 4.1.2         [262402]
ROOT Release   : 5.27/06       [334598]
Creator        : tinti_g
Date           : Wed Jan  4 17:32:09 2012
Host           : Linux lxbuild151.cern.ch 2.6.18-194.11.3.el5.cve20103081 #1 SMP Thu Sep 16 15:17:10 CEST 2010 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /shome/tinti_g/TMVA/test
Training events: 6285
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
NTrees: "50" [Number of trees in the forest]
BoostType: "AdaBoost" [Boosting type for the trees in the forest]
AdaBoostBeta: "5.000000e-01" [Parameter for AdaBoost algorithm]
SeparationType: "giniindex" [Separation criterion for node splitting]
nEventsMin: "350" [Minimum number of events required in a leaf node (default: Classification: max(40, N_train/(Nvar^2)/10), Regression: 10)]
nCuts: "35" [Number of steps during node cut optimisation]
PruneMethod: "nopruning" [Method used for pruning (removal) of statistically insignificant branches]
MaxDepth: "3" [Max depth of the decision tree allowed]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
RenormByClass: "False" [Individually re-normalize each event class to the original size after boosting]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2t (Linear,Quadratic or Exponential)]
UseBaggedGrad: "False" [Use only a random subsample of all events for growing the trees in each iteration. (Only valid for GradBoost)]
GradBaggingFraction: "6.000000e-01" [Defines the fraction of events to be used in each iteration when UseBaggedGrad=kTRUE. (Only valid for GradBoost)]
Shrinkage: "1.000000e+00" [Learning rate for GradBoost algorithm]
UseRandomisedTrees: "False" [Choose at each node splitting a random set of variables]
UseNvars: "3" [Number of variables used if randomised tree option is chosen]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Possion distribution in each split]
UseNTrainEvents: "6285" [Number of randomly picked training events used in randomised (and bagged) trees]
UseWeightedTrees: "True" [Use weighted trees or simple average in classification from the forest]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
PruneStrength: "0.000000e+00" [Pruning strength]
PruneBeforeBoost: "False" [Flag to prune the tree before applying boosting algorithm]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
NNodesMax: "100000" [Max number of nodes in tree]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : Ignore;  Boost With inverse boostweight; Pair events with negative and positive weights in traning sample and *annihilate* them (experimental!); Randomly pair events with negative and positive weights in leaf node and do not boost them (experimental!) ]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 10
alpha                         alpha                         alpha                         pointing angle                                                  'F'    [0.000196760316612,0.199941202998]
fls3d                         fls3d                         fls3d                         3D flight length significance                                   'F'    [5.00184059143,133.894897461]
iso                           iso                           iso                           isolation                                                       'F'    [0.0342738479376,1]
m1pt                          m1pt                          m1pt                          m1pt (GeV)                                                      'F'    [4.50763559341,82.0338287354]
m2pt                          m2pt                          m2pt                          m2pt (GeV)                                                      'F'    [4.00108385086,27.633764267]
m1eta                         m1eta                         m1eta                         m1 #eta                                                         'F'    [-1.3997451067,1.39992165565]
m2eta                         m2eta                         m2eta                         m2 #eta                                                         'F'    [-1.39924478531,1.39976394176]
docatrk                       docatrk                       docatrk                       doca (cm)                                                       'F'    [0.000174304790562,16.9696884155]
pvlips                        pvlips                        pvlips                        PV IP significance                                              'F'    [-4.41180276871,6.06837272644]
closetrk                      closetrk                      closetrk                      N^{#DeltaR}_{trk}                                               'F'    [0,20]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new BDTNode
   
#ifndef BDTNode__def
#define BDTNode__def
   
class BDTNode {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   BDTNode ( BDTNode* left,BDTNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDTNode();

   // test event if it decends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDTNode* GetRight( void )  {return fRight; };

   // test event if it decends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDTNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDTNode*   fLeft;     // pointer to the left daughter node
   BDTNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value appplied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   BDTNode::~BDTNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool BDTNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it decends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool BDTNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it decends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDT : public IClassifierReader {

 public:

   // constructor
   ReadBDT( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadBDT" ),
        fNvars( 10 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "alpha", "fls3d", "iso", "m1pt", "m2pt", "m1eta", "m2eta", "docatrk", "pvlips", "closetrk" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0.000196760316612199;
      fVmax[0] = 0.199941202998161;
      fVmin[1] = 5.00184059143066;
      fVmax[1] = 133.894897460938;
      fVmin[2] = 0.0342738479375839;
      fVmax[2] = 1;
      fVmin[3] = 4.50763559341431;
      fVmax[3] = 82.0338287353516;
      fVmin[4] = 4.0010838508606;
      fVmax[4] = 27.6337642669678;
      fVmin[5] = -1.39974510669708;
      fVmax[5] = 1.39992165565491;
      fVmin[6] = -1.39924478530884;
      fVmax[6] = 1.39976394176483;
      fVmin[7] = 0.000174304790562019;
      fVmax[7] = 16.9696884155273;
      fVmin[8] = -4.41180276870728;
      fVmax[8] = 6.06837272644043;
      fVmin[9] = 0;
      fVmax[9] = 20;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDT() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[10];
   double fVmax[10];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[10];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDTNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDT::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDTNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDTNode*)current->GetRight();
         else current=(BDTNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetNodeType();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
};

void ReadBDT::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(3.18664212467266);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.213796,-99) , 
6, -0.229532, 0, 0, 0.377669,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.0180154,-99) , 
0, 0.0276385, 1, 0, 0.0485625,-99) , 
NN(
0, 
0, 
-1, 0.0282473, 1, -1, 0.00110605,-99) , 
9, 0.555556, 1, 0, 0.00205921,-99)    );
  // itree = 1
  fBoostWeights.push_back(1.7439);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.824132,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.425823,-99) , 
0, 0.0309717, 1, 0, 0.630427,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.0897803,-99) , 
0, 0.0555974, 1, 0, 0.293016,-99) , 
NN(
0, 
0, 
-1, 0.919523, 0, -1, 0.017204,-99) , 
9, 1.11111, 1, 0, 0.0400136,-99)    );
  // itree = 2
  fBoostWeights.push_back(1.13341);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.966478, 0, 1, 0.728771,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.246952,-99) , 
0, 0.0890425, 1, 0, 0.504174,-99) , 
NN(
0, 
0, 
-1, 0.0445844, 1, -1, 0.0486108,-99) , 
2, 0.865871, 0, 0, 0.146272,-99)    );
  // itree = 3
  fBoostWeights.push_back(0.724955);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.747129,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460272,-99) , 
2, 0.966473, 0, 0, 0.565101,-99) , 
NN(
0, 
0, 
-1, 0.134039, 1, -1, 0.285956,-99) , 
9, 3.16667, 1, 0, 0.431754,-99) , 
NN(
0, 
0, 
-1, 0.0504014, 1, -1, 0.0683904,-99) , 
2, 0.758568, 0, 0, 0.232666,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.607734);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.866009, 1, 1, 0.720279,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.576048,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.279885,-99) , 
2, 0.888265, 0, 0, 0.42586,-99) , 
0, 0.0556799, 1, 0, 0.530667,-99) , 
NN(
0, 
0, 
-1, 0.0559399, 1, -1, 0.108254,-99) , 
2, 0.731743, 0, 0, 0.342455,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.450315);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.599909,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.391929,-99) , 
3, 10.7354, 1, 0, 0.528034,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.22738,-99) , 
0, 0.150001, 1, 0, 0.471811,-99) , 
NN(
0, 
0, 
-1, 0.0614784, 1, -1, 0.15309,-99) , 
2, 0.704917, 0, 0, 0.356904,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.404864);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.759547,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.495071,-99) , 
1, 12.1645, 0, 0, 0.635189,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.346226,-99) , 
6, -0.92908, 0, 0, 0.5749,-99) , 
NN(
0, 
0, 
-1, 0.758568, 0, -1, 0.282941,-99) , 
0, 0.0612298, 1, 0, 0.381175,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.348379);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.622875,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.424856,-99) , 
6, -0.699506, 0, 0, 0.562023,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.59309,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.201161,-99) , 
0, 0.0617025, 1, 0, 0.33558,-99) , 
5, 0.855542, 1, 0, 0.525452,-99) , 
NN(
0, 
0, 
-1, 0.0670169, 1, -1, 0.205859,-99) , 
2, 0.651266, 0, 0, 0.448941,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.269341);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.653114,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.477604,-99) , 
2, 0.88244, 1, 0, 0.578649,-99) , 
NN(
0, 
0, 
-1, 0.597614, 0, -1, 0.403739,-99) , 
9, 5.55556, 1, 0, 0.517171,-99) , 
NN(
0, 
0, 
-1, 0.824152, 0, -1, 0.287592,-99) , 
0, 0.127811, 1, 0, 0.448758,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.275917);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.584581,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.304432,-99) , 
1, 33.646, 1, 0, 0.568894,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.562871,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.188049,-99) , 
2, 0.821243, 0, 0, 0.416229,-99) , 
0, 0.127808, 1, 0, 0.526304,-99) , 
NN(
0, 
0, 
-1, 0.105786, 1, -1, 0.238877,-99) , 
2, 0.597614, 0, 0, 0.479895,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.293382);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2.11111, 1, 1, 0.646137,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.430453,-99) , 
7, 0.0537343, 0, 0, 0.45754,-99) , 
2, 0.875101, 1, 0, 0.57307,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558466,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.395597,-99) , 
6, 0.387564, 1, 0, 0.501888,-99) , 
NN(
0, 
0, 
-1, 7.70915, 1, -1, 0.251216,-99) , 
2, 0.785394, 0, 0, 0.391834,-99) , 
0, 0.0556813, 1, 0, 0.448783,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.224282);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.825443,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.49587,-99) , 
2, 0.905648, 1, 0, 0.706797,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.619955,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.450932,-99) , 
6, -0.0685113, 1, 0, 0.533259,-99) , 
0, 0.017456, 1, 0, 0.57813,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.524186,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.319059,-99) , 
5, -0.854679, 0, 0, 0.4782,-99) , 
NN(
0, 
0, 
-1, 7.70915, 1, -1, 0.313507,-99) , 
2, 0.758568, 0, 0, 0.414642,-99) , 
0, 0.0445844, 1, 0, 0.454262,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.2399);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.6003,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.383409,-99) , 
1, 28.3938, 1, 0, 0.563635,-99) , 
7, 0.0537343, 0, 0, 0.57716,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.549919,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.342564,-99) , 
0, 0.143854, 1, 0, 0.492831,-99) , 
NN(
0, 
0, 
-1, 0.758568, 0, -1, 0.347663,-99) , 
3, 7.6978, 1, 0, 0.415223,-99) , 
0, 0.0445844, 1, 0, 0.454415,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.160952);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.996252,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.544709,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.369608,-99) , 
5, 0.855542, 1, 0, 0.517079,-99) , 
7, 0.0538666, 0, 0, 0.536009,-99) , 
NN(
0, 
0, 
-1, 13.1217, 1, -1, 0.41801,-99) , 
9, 2.22222, 1, 0, 0.458254,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.0915573);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.774549,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.499157,-99) , 
2, 0.905648, 1, 0, 0.668606,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500111,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.369058,-99) , 
5, 0.933311, 1, 0, 0.480632,-99) , 
NN(
0, 
0, 
-1, -0.466916, 0, -1, 0.329243,-99) , 
2, 0.570788, 0, 0, 0.462434,-99) , 
0, 0.0168421, 1, 0, 0.474846,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.112631);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, -0.035234, 0, 1, 0.6659,-99) , 
NN(
0, 
0, 
-1, 12.638, 1, -1, 0.450872,-99) , 
0, 0.0168421, 1, 0, 0.463671,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.129905);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.536729,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.346063,-99) , 
5, 1.20551, 1, 0, 0.522465,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.508997,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.292229,-99) , 
1, 8.59644, 1, 0, 0.407958,-99) , 
5, -0.933134, 0, 0, 0.502793,-99) , 
NN(
0, 
0, 
-1, 0.698547, 0, -1, 0.334746,-99) , 
0, 0.172199, 1, 0, 0.488377,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.150446);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.546532,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.3925,-99) , 
6, 0.934356, 1, 0, 0.512456,-99) , 
NN(
0, 
0, 
-1, 0.576783, 0, -1, 0.421708,-99) , 
5, -0.466523, 0, 0, 0.480476,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.285242,-99) , 
3, 19.5822, 1, 0, 0.469679,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.141219);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, -0.035234, 0, 1, 0.638942,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.528211,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.421665,-99) , 
1, 9.09785, 1, 0, 0.482789,-99) , 
NN(
0, 
0, 
-1, 0.785394, 0, -1, 0.359889,-99) , 
3, 12.638, 1, 0, 0.460683,-99) , 
0, 0.0168421, 1, 0, 0.471124,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.152277);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.54542,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.410206,-99) , 
1, 7.92763, 0, 0, 0.513961,-99) , 
7, 0.0536951, 0, 0, 0.522922,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.516147,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.398847,-99) , 
1, 8.69639, 1, 0, 0.480325,-99) , 
NN(
0, 
0, 
-1, 7.6579, 1, -1, 0.300261,-99) , 
2, 0.704917, 0, 0, 0.432357,-99) , 
0, 0.0723267, 1, 0, 0.470728,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.120346);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.592626,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.481346,-99) , 
1, 15.7444, 0, 0, 0.501567,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.397609,-99) , 
6, -1.01002, 0, 0, 0.4866,-99) , 
NN(
0, 
0, 
-1, 0.849273, 0, -1, 0.392636,-99) , 
0, 0.127811, 1, 0, 0.461117,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.182382);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.128169, 1, 1, 0.633525,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.440986,-99) , 
2, 0.849273, 1, 0, 0.546177,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.670464,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.499884,-99) , 
5, -0.314059, 0, 0, 0.600598,-99) , 
NN(
0, 
0, 
-1, 0.16665, 1, -1, 0.41806,-99) , 
2, 0.946349, 0, 0, 0.455788,-99) , 
3, 6.66114, 1, 0, 0.48424,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.127521);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.0288063, 1, 1, 0.541915,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.368618,-99) , 
1, 30.0657, 1, 0, 0.530942,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.54428,-99) , 
NN(
0, 
0, 
-1, 7.27642, 1, -1, 0.323811,-99) , 
2, 0.849273, 0, 0, 0.440312,-99) , 
0, 0.127811, 1, 0, 0.506574,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.0972905);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.0537343, 0, 1, 0.534117,-99) , 
NN(
0, 
0, 
-1, 11.0226, 1, -1, 0.453342,-99) , 
9, 5.55556, 1, 0, 0.500716,-99) , 
NN(
0, 
0, 
-1, 0.117066, 1, -1, 0.398202,-99) , 
5, 0.933311, 1, 0, 0.485642,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.0918104);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.520981,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.402892,-99) , 
6, -1.01002, 0, 0, 0.504695,-99) , 
NN(
0, 
0, 
-1, 0.698547, 0, -1, 0.375396,-99) , 
0, 0.172199, 1, 0, 0.493792,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.341126,-99) , 
3, 19.5822, 1, 0, 0.485562,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.0718137);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.995323,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.490902,-99) , 
7, 0.0536951, 0, 0, 0.497235,-99) , 
NN(
0, 
0, 
-1, 0.11132, 1, -1, 0.39388,-99) , 
5, 1.01108, 1, 0, 0.483747,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.359936,-99) , 
8, -1.50064, 0, 0, 0.47413,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.0640759);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.0536951, 0, 1, 0.514746,-99) , 
NN(
0, 
0, 
-1, 0.11132, 1, -1, 0.411149,-99) , 
5, 1.01108, 1, 0, 0.501304,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.376641,-99) , 
8, -1.50064, 0, 0, 0.491693,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.073903);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
0, 
0, 
-1, 28.3934, 1, -1, 0.485549,-99) , 
7, 0.0536951, 0, 0, 0.492908,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.561962,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.291196,-99) , 
6, 0.550875, 1, 0, 0.451309,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.235872,-99) , 
5, -0.389239, 0, 0, 0.395827,-99) , 
2, 0.570788, 0, 0, 0.481947,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.0773669);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.513274,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.321049,-99) , 
1, 28.3934, 1, 0, 0.504021,-99) , 
7, 0.0536951, 0, 0, 0.510864,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.530359,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.379171,-99) , 
5, 0.309781, 0, 0, 0.449583,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.249682,-99) , 
3, 10.3308, 1, 0, 0.396871,-99) , 
2, 0.570788, 0, 0, 0.49811,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.124951);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.739754,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.478509,-99) , 
8, -0.035234, 0, 0, 0.599036,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.525604,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441536,-99) , 
5, 0.698229, 1, 0, 0.505435,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.642191,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.412509,-99) , 
7, 0.0304619, 0, 0, 0.435422,-99) , 
1, 9.09785, 1, 0, 0.476048,-99) , 
0, 0.0168421, 1, 0, 0.4832,-99)    );
  // itree = 30
  fBoostWeights.push_back(0.0887632);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541608,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.386431,-99) , 
1, 28.3938, 1, 0, 0.520498,-99) , 
7, 0.0537343, 0, 0, 0.529209,-99) , 
NN(
0, 
0, 
-1, 0.570788, 0, -1, 0.462958,-99) , 
0, 0.0556813, 1, 0, 0.484222,-99)    );
  // itree = 31
  fBoostWeights.push_back(0.0479153);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.0536951, 0, 1, 0.510698,-99) , 
NN(
0, 
0, 
-1, 0.465282, 1, -1, 0.425376,-99) , 
2, 0.572941, 0, 0, 0.501117,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.368596,-99) , 
3, 19.5822, 1, 0, 0.494041,-99)    );
  // itree = 32
  fBoostWeights.push_back(0.136077);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.466761, 1, 1, 0.572265,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.42503,-99) , 
2, 0.899516, 1, 0, 0.527331,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.606342,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.450003,-99) , 
1, 12.1794, 1, 0, 0.563334,-99) , 
NN(
0, 
0, 
-1, 0.16665, 1, -1, 0.441592,-99) , 
2, 0.946349, 0, 0, 0.466668,-99) , 
3, 6.66114, 1, 0, 0.485873,-99)    );
  // itree = 33
  fBoostWeights.push_back(0.0715301);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0.0085139, 0, 1, 0.613802,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.589445,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486506,-99) , 
7, 0.0204192, 0, 0, 0.500422,-99) , 
NN(
0, 
0, 
-1, -0.466916, 0, -1, 0.410288,-99) , 
2, 0.570788, 0, 0, 0.490739,-99) , 
0, 0.0168421, 1, 0, 0.497946,-99)    );
  // itree = 34
  fBoostWeights.push_back(0.0899522);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.550376,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.481029,-99) , 
6, 0.529639, 1, 0, 0.527753,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.450756,-99) , 
6, -1.01002, 0, 0, 0.517392,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.502913,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0,-99) , 
2, 0.698547, 0, 0, 0.418631,-99) , 
0, 0.172199, 1, 0, 0.509691,-99)    );
  // itree = 35
  fBoostWeights.push_back(0.0875159);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.531069,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.353177,-99) , 
1, 35.7137, 1, 0, 0.524664,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514897,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.370119,-99) , 
8, -0.557812, 0, 0, 0.460405,-99) , 
5, -0.933134, 0, 0, 0.513707,-99) , 
NN(
0, 
0, 
-1, 0.698547, 0, -1, 0.402938,-99) , 
0, 0.172199, 1, 0, 0.505103,-99)    );
  // itree = 36
  fBoostWeights.push_back(0.0451123);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.574551,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500599,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.398974,-99) , 
2, 0.597614, 0, 0, 0.490142,-99) , 
9, 14.4444, 0, 0, 0.497506,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.403374,-99) , 
8, -1.50064, 0, 0, 0.490391,-99)    );
  // itree = 37
  fBoostWeights.push_back(0.0632126);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.512155,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.340617,-99) , 
1, 31.1617, 1, 0, 0.504854,-99) , 
NN(
0, 
0, 
-1, 0.600295, 0, -1, 0.457862,-99) , 
5, -0.466523, 0, 0, 0.488419,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.38273,-99) , 
3, 19.5822, 1, 0, 0.48276,-99)    );
  // itree = 38
  fBoostWeights.push_back(0.121659);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.61172,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.632828,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.135466,-99) , 
2, 0.962259, 1, 0, 0.355374,-99) , 
9, 0.527778, 0, 0, 0.549189,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.637188,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.469884,-99) , 
9, 0.555556, 1, 0, 0.483141,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.380476,-99) , 
3, 14.2641, 1, 0, 0.470477,-99) , 
0, 0.027939, 1, 0, 0.4799,-99)    );
  // itree = 39
  fBoostWeights.push_back(0.0721135);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.523843,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.413568,-99) , 
8, -1.50064, 0, 0, 0.516278,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505838,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.366792,-99) , 
2, 0.785394, 0, 0, 0.452394,-99) , 
3, 13.1217, 1, 0, 0.505275,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.395416,-99) , 
5, 1.24438, 1, 0, 0.500281,-99)    );
  // itree = 40
  fBoostWeights.push_back(0.0781368);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.0537343, 0, 1, 0.513437,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.571994,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.423468,-99) , 
9, 14.2222, 0, 0, 0.460491,-99) , 
9, 6.11111, 1, 0, 0.4948,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.42677,-99) , 
6, 1.08876, 1, 0, 0.488099,-99)    );
  // itree = 41
  fBoostWeights.push_back(0.0936168);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.56511,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.488959,-99) , 
6, -0.699553, 1, 0, 0.50769,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501637,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.358236,-99) , 
6, -0.310407, 0, 0, 0.445333,-99) , 
1, 9.57614, 1, 0, 0.494841,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.993934,-99) , 
NN(
0, 
0, 
-1, 0.0558907, 1, -1, 0.420735,-99) , 
7, 0.0536451, 0, 0, 0.441593,-99) , 
1, 12.1626, 1, 0, 0.481668,-99)    );
  // itree = 42
  fBoostWeights.push_back(0.0901161);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.647484,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486644,-99) , 
3, 9.36324, 0, 0, 0.564589,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.51348,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.29869,-99) , 
2, 0.598062, 0, 0, 0.493231,-99) , 
8, 0.677832, 0, 0, 0.5138,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.99277,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479599,-99) , 
7, 0.0536451, 0, 0, 0.488515,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.13274,-99) , 
0, 0.155448, 1, 0, 0.471185,-99) , 
1, 8.5822, 1, 0, 0.493324,-99)    );
  // itree = 43
  fBoostWeights.push_back(0.0662558);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.539687,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.485277,-99) , 
2, 0.850121, 1, 0, 0.515255,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500168,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.271363,-99) , 
2, 0.648305, 0, 0, 0.466282,-99) , 
0, 0.127811, 1, 0, 0.5019,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.411399,-99) , 
3, 19.5822, 1, 0, 0.497121,-99)    );
  // itree = 44
  fBoostWeights.push_back(0.112373);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.555963,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.424876,-99) , 
0, 0.099333, 1, 0, 0.529126,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.469154,-99) , 
7, 0.0537343, 0, 0, 0.478251,-99) , 
2, 0.865871, 1, 0, 0.507951,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.528633,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441686,-99) , 
3, 7.29501, 1, 0, 0.483452,-99) , 
NN(
0, 
0, 
-1, -0.00175297, 0, -1, 0.281424,-99) , 
2, 0.648305, 0, 0, 0.454037,-99) , 
0, 0.127811, 1, 0, 0.493809,-99)    );
  // itree = 45
  fBoostWeights.push_back(0.123677);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.56495,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.462793,-99) , 
0, 0.0890951, 0, 0, 0.511982,-99) , 
7, 0.0537343, 0, 0, 0.519706,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.527242,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.362692,-99) , 
4, 6.62694, 1, 0, 0.496771,-99) , 
NN(
0, 
0, 
-1, 9.44444, 0, -1, 0.325854,-99) , 
0, 0.144556, 1, 0, 0.472774,-99) , 
2, 0.839046, 0, 0, 0.496288,-99)    );
  // itree = 46
  fBoostWeights.push_back(0.0997274);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.599177,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486918,-99) , 
4, 6.61265, 0, 0, 0.513207,-99) , 
7, 0.0537343, 0, 0, 0.520487,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.546091,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.450235,-99) , 
9, 2.22222, 1, 0, 0.471473,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.264975,-99) , 
0, 0.172249, 1, 0, 0.460073,-99) , 
2, 0.839046, 0, 0, 0.490357,-99)    );
  // itree = 47
  fBoostWeights.push_back(0.0993993);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558218,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48635,-99) , 
4, 5.04599, 0, 0, 0.526539,-99) , 
7, 0.0537343, 0, 0, 0.533294,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.545299,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.454241,-99) , 
3, 6.66114, 1, 0, 0.484011,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.259439,-99) , 
0, 0.177787, 1, 0, 0.474404,-99) , 
2, 0.839046, 0, 0, 0.503952,-99)    );
  // itree = 48
  fBoostWeights.push_back(0.112664);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.233394, 0, 1, 0.579457,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.529656,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.445564,-99) , 
6, 0.622414, 1, 0, 0.508081,-99) , 
2, 0.946349, 0, 0, 0.521633,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.560647,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.41718,-99) , 
8, -0.0485405, 0, 0, 0.496597,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.323056,-99) , 
1, 9.00258, 1, 0, 0.465439,-99) , 
0, 0.127811, 1, 0, 0.506983,-99)    );
  // itree = 49
  fBoostWeights.push_back(0.0911344);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 1,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.515802,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.371521,-99) , 
1, 25.7529, 1, 0, 0.507058,-99) , 
7, 0.0537343, 0, 0, 0.512841,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.560348,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.436602,-99) , 
9, 9.44444, 0, 0, 0.480255,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.200646,-99) , 
0, 0.172249, 1, 0, 0.467659,-99) , 
2, 0.785394, 0, 0, 0.495473,-99)    );
   return;
};
 
// Clean up
inline void ReadBDT::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadBDT::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
